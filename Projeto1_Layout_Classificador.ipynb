{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: André Barboza de Braga Melo\n",
    "\n",
    "Nome: Rodrigo Anciães Patelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\andre\\Downloads\\Projeto-1-CDados-main\\Projeto-1-CDados-main\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'League of Legends_classificado.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nao aguento mais jogar league of legends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ainda vou enfartar jogando league of legends\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chegou a hora! está começando o primeiro episó...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@danielxd__1 • otaku viciado em doraminha core...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q dificil ser ruim nesse tal de league of legends</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0           nao aguento mais jogar league of legends           1\n",
       "1  ainda vou enfartar jogando league of legends\\n...           1\n",
       "2  chegou a hora! está começando o primeiro episó...           0\n",
       "3  @danielxd__1 • otaku viciado em doraminha core...           0\n",
       "4  q dificil ser ruim nesse tal de league of legends           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meus top artistas do spotify nas últimas seman...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"enquanto estiver de pé\" foi a música-tema do ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grevtar monstro sagrado do league of legends n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@pedroxdgameplay league of legends é de graça ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red canids kalunga é a grande vencedora do cam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevância\n",
       "0  meus top artistas do spotify nas últimas seman...           0\n",
       "1  \"enquanto estiver de pé\" foi a música-tema do ...           0\n",
       "2  grevtar monstro sagrado do league of legends n...           0\n",
       "3  @pedroxdgameplay league of legends é de graça ...           1\n",
       "4  red canids kalunga é a grande vencedora do cam...           0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "ESCREVA AQUI... O produto que nós escolhemos é um videogame online muito famoso e popular chamado de League of Legends. Esse jogo tem um grande teor competitivo, porém sofre muito com toxicidade dos jogadores e ele é em geral grande alvo do ódio dos próprios jogadores. Para classifcar um tweet como relevante nós consideramos todos os que possuem opniões sobre o jogo como todo (desconsiderando opniões sobre personagens) e qualquer pessoa chamando outras para jogar, ambas essas considerções podem mostrar uma visão de como está a popularidade do jogo e como estão reagindo a ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6f789cd71355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "#Importando oque é permitido e nescessário\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "import re\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;|•]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emoji' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a519fd70e848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Treinamento'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfrase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdemojize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m#teste = frase.split(' :')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#teste = teste.split(':')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emoji' is not defined"
     ]
    }
   ],
   "source": [
    "for frase in train['Treinamento']:\n",
    "    frase = cleanup(frase)\n",
    "    frase = emoji.demojize(frase)\n",
    "    #teste = frase.split(' :')\n",
    "    #teste = teste.split(':')\n",
    "    print(frase)\n",
    "    #print(teste)\n",
    "    #testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainR = train.loc[train['Relevância']==1]\n",
    "trainR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainR['Treinamento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainI = train.loc[train['Relevância']==0]\n",
    "trainI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainI['Treinamento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criarei uma lista com todas as palavras de cada situação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_total = ''\n",
    "for frase in train['Treinamento']:\n",
    "    frase = emoji.demojize(frase)\n",
    "    frase.strip('\\n')\n",
    "    frase = cleanup(frase)\n",
    "    lista_total += frase\n",
    "lista_total = lista_total.split(' ')\n",
    "#lista_total\n",
    "serie_total = pd.Series(lista_total)\n",
    "serie_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_re = ''\n",
    "for frase in trainR['Treinamento']:\n",
    "    frase = emoji.demojize(frase)\n",
    "    frase.strip('\\n')\n",
    "    frase = cleanup(frase)\n",
    "    lista_re += frase\n",
    "lista_re = lista_re.split(' ')\n",
    "#lista_re\n",
    "serie_re = pd.Series(lista_re)\n",
    "serie_re.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_ir = ''\n",
    "for frase in trainI['Treinamento']:\n",
    "    frase = emoji.demojize(frase)\n",
    "    frase.strip('\\n')\n",
    "    frase = cleanup(frase)\n",
    "    lista_ir += frase\n",
    "lista_ir = lista_ir.split(' ')\n",
    "#lista_ir\n",
    "serie_ir = pd.Series(lista_ir)\n",
    "serie_ir.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia_total = serie_total.value_counts()\n",
    "frequencia_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia_re = serie_re.value_counts()\n",
    "frequencia_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia_ir = serie_ir.value_counts()\n",
    "frequencia_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probR = len(lista_re)/len(lista_total)\n",
    "probR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probI = len(lista_ir)/len(lista_total)\n",
    "probI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevante\n",
    "l_teste = []\n",
    "for frase in train['Treinamento']:\n",
    "    prob_frase_R = 1\n",
    "    frase = emoji.demojize(frase)\n",
    "    frase.strip('\\n')\n",
    "    frase = cleanup(frase)\n",
    "    palavras = frase.split(' ')\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        if palavra in frequencia_re:\n",
    "            pro = (frequencia_re[palavra]+1)/(len(frequencia_re) + len(frequencia_total))\n",
    "            #print('funciona')\n",
    "        else:\n",
    "            pro = 1/(len(frequencia_re) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "            #print('funciona tbm')\n",
    "        prob_frase_R *= pro\n",
    "    l_teste.append(prob_frase_R * probR)\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Irelevante\n",
    "IR_teste = []\n",
    "for frase in train['Treinamento']:\n",
    "    prob_frase_IR = 1\n",
    "    frase = emoji.demojize(frase)\n",
    "    frase.strip('\\n')\n",
    "    frase = cleanup(frase)\n",
    "    palavras = frase.split(' ')\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        if palavra in frequencia_ir:\n",
    "            pro = (frequencia_ir[palavra]+1)/(len(frequencia_ir) + len(frequencia_total))\n",
    "            #print('funciona')\n",
    "        else:\n",
    "            pro = 1/(len(frequencia_ir) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "            #print('funciona tbm')\n",
    "        prob_frase_IR *= pro\n",
    "    IR_teste.append(prob_frase_IR * probI)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "classificacao = []\n",
    "while i < len(train['Treinamento']):\n",
    "    qual_e = 1\n",
    "    if l_teste[i]< IR_teste[i]:\n",
    "        cl = 0\n",
    "    else:\n",
    "        cl = 1\n",
    "        \n",
    "    classificacao.append(cl)\n",
    "    i += 1\n",
    "    \n",
    "classificacao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = train\n",
    "final_train['classificador'] = classificacao\n",
    "pd.set_option('display.max_columns', None)\n",
    "final_train.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train['classificador'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fe4ba45b4f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Relevância'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classificador'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0manalise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_train' is not defined"
     ]
    }
   ],
   "source": [
    "analise = pd.crosstab(final_train['Relevância'], final_train['classificador'],normalize=True)\n",
    "analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora parece certo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador(train, tweets):\n",
    "    \n",
    "    trainR = train.loc[train['Relevância']==1]\n",
    "    trainI = train.loc[train['Relevância']==0]\n",
    "    \n",
    "    lista_total = ''    \n",
    "    for frase in train[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_total += frase\n",
    "    lista_total = lista_total.split(' ')\n",
    "    #lista_total\n",
    "    serie_total = pd.Series(lista_total)\n",
    "\n",
    "    \n",
    "    lista_re = ''\n",
    "    for frase in trainR[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_re += frase\n",
    "    lista_re = lista_re.split(' ')\n",
    "    #lista_re\n",
    "    serie_re = pd.Series(lista_re)\n",
    "    \n",
    "    lista_ir = ''\n",
    "    for frase in trainI[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_ir += frase\n",
    "    lista_ir = lista_ir.split(' ')\n",
    "    #lista_ir\n",
    "    serie_ir = pd.Series(lista_ir)\n",
    "    \n",
    "    frequencia_total = serie_total.value_counts()\n",
    "    frequencia_re = serie_re.value_counts()\n",
    "    frequencia_ir = serie_ir.value_counts()\n",
    "    \n",
    "    probR = len(lista_re)/len(lista_total)\n",
    "    probI = len(lista_ir)/len(lista_total)\n",
    "    \n",
    "    #relevante\n",
    "    l_teste = []\n",
    "    for frase in train[tweets]:\n",
    "        prob_frase_R = 1\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        palavras = frase.split(' ')    \n",
    "        for palavra in palavras:\n",
    "            if palavra in frequencia_re:\n",
    "                pro = (frequencia_re[palavra]+1)/(len(frequencia_re) + len(frequencia_total))\n",
    "                #print('funciona')\n",
    "            else:\n",
    "                pro = 1/(len(frequencia_re) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "                #print('funciona tbm')\n",
    "            prob_frase_R *= pro\n",
    "        l_teste.append(prob_frase_R * probR)\n",
    "        \n",
    "    #Irelevante\n",
    "    IR_teste = []\n",
    "    for frase in train[tweets]:\n",
    "        prob_frase_IR = 1\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        palavras = frase.split(' ')\n",
    "    \n",
    "        for palavra in palavras:\n",
    "            if palavra in frequencia_ir:\n",
    "                pro = (frequencia_ir[palavra]+1)/(len(frequencia_ir) + len(frequencia_total))\n",
    "                #print('funciona')\n",
    "            else:\n",
    "                pro = 1/(len(frequencia_ir) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "                #print('funciona tbm')\n",
    "            prob_frase_IR *= pro\n",
    "        IR_teste.append(prob_frase_IR * probI)\n",
    "        \n",
    "    i = 0\n",
    "    classificacao = []\n",
    "    while i < len(train[tweets]):\n",
    "        qual_e = 1\n",
    "        if l_teste[i]< IR_teste[i]:\n",
    "            cl = 0\n",
    "        else:\n",
    "            cl = 1\n",
    "        \n",
    "        classificacao.append(cl)\n",
    "        i += 1\n",
    "    \n",
    "    final_train = train\n",
    "    final_train['classificador'] = classificacao\n",
    "    \n",
    "    return final_train\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#esse daqui é só um teste sem fundamento teoricamente então por enquanto ignore\n",
    "\n",
    "#Aqui agente só ta fezendo ele funcionar permanentemente só com o treinamento\n",
    "\n",
    "def classificador_aprende(train, tweets, teste, tweets_teste):\n",
    "    \n",
    "    trainR = train.loc[train['Relevância']==1]\n",
    "    trainI = train.loc[train['Relevância']==0]\n",
    "    \n",
    "    lista_total = ''    \n",
    "    for frase in train[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_total += frase\n",
    "    lista_total = lista_total.split(' ')\n",
    "    #lista_total\n",
    "    serie_total = pd.Series(lista_total)\n",
    "\n",
    "    \n",
    "    lista_re = ''\n",
    "    for frase in trainR[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_re += frase\n",
    "    lista_re = lista_re.split(' ')\n",
    "    #lista_re\n",
    "    serie_re = pd.Series(lista_re)\n",
    "    \n",
    "    lista_ir = ''\n",
    "    for frase in trainI[tweets]:\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        lista_ir += frase\n",
    "    lista_ir = lista_ir.split(' ')\n",
    "    #lista_ir\n",
    "    serie_ir = pd.Series(lista_ir)\n",
    "    \n",
    "    frequencia_total = serie_total.value_counts()\n",
    "    frequencia_re = serie_re.value_counts()\n",
    "    frequencia_ir = serie_ir.value_counts()\n",
    "    \n",
    "    probR = len(lista_re)/len(lista_total)\n",
    "    probI = len(lista_ir)/len(lista_total)\n",
    "    \n",
    "    #relevante\n",
    "    l_teste = []\n",
    "    for frase in teste[tweets_teste]:\n",
    "        prob_frase_R = 1\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        palavras = frase.split(' ')    \n",
    "        for palavra in palavras:\n",
    "            if palavra in frequencia_re:\n",
    "                pro = (frequencia_re[palavra]+1)/(len(frequencia_re) + len(frequencia_total))\n",
    "                #print('funciona')\n",
    "            else:\n",
    "                pro = 1/(len(frequencia_re) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "                #print('funciona tbm')\n",
    "            prob_frase_R *= pro\n",
    "        l_teste.append(prob_frase_R * probR)\n",
    "        \n",
    "    #Irelevante\n",
    "    IR_teste = []\n",
    "    for frase in teste[tweets_teste]:\n",
    "        prob_frase_IR = 1\n",
    "        frase = emoji.demojize(frase)\n",
    "        frase.strip('\\n')\n",
    "        frase = cleanup(frase)\n",
    "        palavras = frase.split(' ')\n",
    "    \n",
    "        for palavra in palavras:\n",
    "            if palavra in frequencia_ir:\n",
    "                pro = (frequencia_ir[palavra]+1)/(len(frequencia_ir) + len(frequencia_total))\n",
    "                #print('funciona')\n",
    "            else:\n",
    "                pro = 1/(len(frequencia_ir) + len(frequencia_total)) #Esse daqui é um TESTE pra suavização, não foi feito com o objetivo de estar certo\n",
    "                #print('funciona tbm')\n",
    "            prob_frase_IR *= pro\n",
    "        IR_teste.append(prob_frase_IR * probI)\n",
    "        \n",
    "    i = 0\n",
    "    classificacao = []\n",
    "    while i < len(teste[tweets_teste]):\n",
    "        qual_e = 1\n",
    "        if l_teste[i]< IR_teste[i]:\n",
    "            cl = 0\n",
    "        else:\n",
    "            cl = 1\n",
    "        \n",
    "        classificacao.append(cl)\n",
    "        i += 1\n",
    "    \n",
    "    final_train = teste\n",
    "    final_train['classificador'] = classificacao\n",
    "    \n",
    "    return final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classf = classificador(test, 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa parte de baixo é só um teste que funciona só com o treinamneto para classificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_t = pd.crosstab(test_classf['Relevância'], test_classf['classificador'],normalize=True)\n",
    "analise_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctg_verd_posit = analise_t.iloc[1,1]/(analise_t.iloc[1,1] + analise_t.iloc[1,0])\n",
    "pctg_falso_negat = analise_t.iloc[1,0]/(analise_t.iloc[1,1] + analise_t.iloc[1,0])\n",
    "pctg_verd_negat = analise_t.iloc[0,0]/(analise_t.iloc[0,0] + analise_t.iloc[0,1])\n",
    "pctg_falso_posit = analise_t.iloc[0,1]/(analise_t.iloc[0,0] + analise_t.iloc[0,1])\n",
    "\n",
    "print('O classificador acertou a classificação de {0:.2f} das mensagens irrelevantes e errou {1:.2f}'.format(pctg_verd_negat,pctg_falso_posit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classf_aprende = classificador_aprende(train,'Treinamento', test, 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classf_aprende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_tap = pd.crosstab(test_classf_aprende['Relevância'], test_classf_aprende['classificador'],normalize=True)\n",
    "analise_tap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, é essencial esclarecer que o método de classificação utilizado para separar os tweets entre relevantes ou irrelevantes foi baseado, respectivamente, na expressão - ou não expressão - de opinião acerca do produto.\n",
    "\n",
    "Nota-se que o primeiro classificador conseguiu, através do método Naive-Bayes, obter uma porcentagem de classificações corretas de 95% dos tweets. Resultado surpreeendente, visto o método utilizado, que deixa espaço para para erros, uma vez que não considera a semântica das frases e palavras.\n",
    "\n",
    "Considerando esta inabilidade de identificar o sentido semântico do texto, textos com sarcasmo ou dupla negação foram classificados na maioria das vezes como sendo relevantes (que expressam opinião) devido ao conteúdo lexical ou à própria grafia informal das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
